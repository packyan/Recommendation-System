{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立物品到用户 倒排表\n",
    "表示某个物品，被哪几名用户访问过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def UsersSimilarity(train_set):\n",
    "    \n",
    "    #建立物品到用户 倒排表\n",
    "    \n",
    "    item2user = dict()\n",
    "    for user, items in train_set.items():\n",
    "        for item in items:\n",
    "            if item not in item2user:\n",
    "                item2user[item] = []\n",
    "            item2user[item].append(user)\n",
    "            \n",
    "    users_similarity_matrix = {}\n",
    "    \n",
    "    for items, users in item2user.items():\n",
    "        for user_i in users:\n",
    "            for user_j in users:\n",
    "                #排除掉自己，i,i\n",
    "                if user_i == user_j:\n",
    "                    continue\n",
    "                #default -- 键不存在时，设置的默认键值。\n",
    "                users_similarity_matrix.setdefault(user_i, {})\n",
    "                users_similarity_matrix[user_i].setdefault(user_j, 0)\n",
    "                users_similarity_matrix[user_i][user_j] += 1\n",
    "                #C[u][v] += 1 / math.log(1 + len(users)) \n",
    "    #user_sim {1:{2:6, 4:10} }  一号用户 与 2 号相似6 与 4号相似10      \n",
    "    #。扫描完所有物品后，我们可以得到最终的W矩阵。\n",
    "#这里的W是余弦相似度中的分子部分，然后将W除以分母可以得到最终的用户兴趣相似度。\n",
    "    for user, related_users in users_similarity_matrix.items():\n",
    "        for user_j, cuv in related_users.items():\n",
    "            users_similarity_matrix[user_i][user_j] = cuv/math.sqrt(len(train_set[user] * len(train_set[user_j])))                                                                  \n",
    "    return users_similarity_matrix                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliting data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "import os \n",
    "\n",
    "M = 5\n",
    "data = dataloader.load_data(os.path.join(os.getcwd(),'Data','ratings.dat'))\n",
    "train_set, test_set = dataloader.split_data(data, M, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1193', '3408', '2355', '1287', '2804', '594', '919', '595', '2398', '2791', '2018', '2797', '1270', '527', '48', '1097', '1721', '1545', '2294', '3186', '1566', '588', '1907', '783', '1836', '1022', '2762', '150', '1', '1962', '260', '1028', '1029', '1207', '2028', '531', '3114', '1246']\n",
      "*********\n",
      "\n",
      "['938', '2918', '1035', '3105', '1961', '2692', '608']\n"
     ]
    }
   ],
   "source": [
    "print(train_set[1])\n",
    "print('*********\\n')\n",
    "print(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim_matrix = UsersSimilarity(train_set)\n",
    "# takes a long time about half an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict2json(file_name, dic): \n",
    "    import json\n",
    "    with open(file_name+'.json','a') as outfile:\n",
    "        json.dump(dic,outfile,ensure_ascii=False)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "def read_json2dict(file_path):\n",
    "    import json\n",
    "    data = []\n",
    "    with  open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    f.close()\n",
    "    if len(data) ==  1:\n",
    "        return data[0]\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict2json('user_sim_matrix', user_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到一个用户之间的相似度矩阵 N*N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。\n",
    "#这里选50个，选出50个与某用户最接近的K个用户。\n",
    "similarity_user = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend(user, train_set, W, k = similarity_user):\n",
    "    already_view_items = train_set[user] \n",
    "    rank = dict()\n",
    "    for user_j, weight_user_ij in sorted(W[user].items(), key = lambda w_user_j: w_user_j[1],reverse=True)[:k]:\n",
    "        for items in train_set[user_j]:\n",
    "            if items in already_view_items:\n",
    "                continue;\n",
    "            else:\n",
    "                rank.setdefault(items, 0)\n",
    "                rank[items] += weight_user_ij\n",
    "                # real is  += weight_user_ij * rvi\n",
    "    return sorted(rank.items(), key = lambda w:w[1], reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3034', 129),\n",
       " ('923', 129),\n",
       " ('2268', 129),\n",
       " ('3499', 129),\n",
       " ('608', 129),\n",
       " ('2329', 129),\n",
       " ('2336', 129),\n",
       " ('3147', 129),\n",
       " ('141', 129),\n",
       " ('1784', 129)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend(1,train_set,user_sim_matrix, k = 5)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend2(user, train, W,   k = similarity_user):\n",
    "    rank = dict()\n",
    "    from operator import itemgetter\n",
    "    watched_items = train[user]\n",
    "    for v, wuv in sorted(W[user].items(),key=itemgetter(1), reverse=True)[:k]:      #obtained most k user which similarity given user\n",
    "        for movie in train[v]:\n",
    "            if movie in watched_items:\n",
    "                continue\n",
    "            rank.setdefault(movie, 0)\n",
    "            rank[movie] += wuv\n",
    "    #return most n movies which have large probability given user will like these. Return type: [{movieID: similarity score}, {},...,{}]\n",
    "    return sorted(rank.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  myEvalution():\n",
    "    def __init__(self, train_set, test_set, users_sim_matrix, TopN = 10):\n",
    "        self.train = train_set\n",
    "        self.test = test_set\n",
    "        self.N = TopN\n",
    "        self.sim_mat = users_sim_matrix\n",
    "        self.hit = 0\n",
    "        self.all = 0\n",
    "        self.recommend_items = set()\n",
    "        self.all_items = set()\n",
    "        \n",
    "    def run(self):\n",
    "        for users in train_set.keys():\n",
    "            for item in self.train[users]:\n",
    "                self.all_items.add(item)\n",
    "                #add all different items \n",
    "            tu = self.test.get(users, {}) #获得测试集中的user 评分电影 如果没有返回空{}\n",
    "\n",
    "            #计算user最感兴趣的前N个items\n",
    "            Init_rank = Recommend(users, self.train, self.sim_mat, k = similarity_user)\n",
    "            rank = Init_rank[:self.N]\n",
    "\n",
    "            for item, weight in rank:\n",
    "                if item in tu:\n",
    "                    self.hit += 1\n",
    "                    #计算 推荐和 测试集上的交集\n",
    "                self.recommend_items.add(item)\n",
    "            self.all += len(tu)\n",
    "    \n",
    "    def recall(self):\n",
    "        #召回率， 对用户推荐的N个item 与 测试集 item 交集， 除以测试集中的数量\n",
    "        #预测出来正确的个数 /  真正为正确的个数\n",
    "        return self.hit / (self.all * 1.0) *100\n",
    "    \n",
    "    def precision(self):\n",
    "        #预测出来正确的个数 / 预测的总个数\n",
    "        return self.hit / ((len(self.train) * self.N * 1.0))*100\n",
    "    \n",
    "    def coverage(self):\n",
    "        \n",
    "        return len(self.recommend_items) / (len(self.all_items) * 1.0) *100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myEvalution(train_set, test_set, user_sim_matrix)\n",
    "model.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is 5.230972 % , precision is 17.306291 % , coverage is 13.302503 %\n"
     ]
    }
   ],
   "source": [
    "print('recall is {:5f} % , precision is {:5f} % , coverage is {:5f} %'.format(model.recall(), model.precision(), model.coverage()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall is 5.230972 % , precision is 17.306291 % , coverage is 13.302503 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.22892164982607255\n",
      "\n",
      "\n",
      "Recall:  0.11968165718393044\n",
      "\n",
      "\n",
      "Coverage:  0.17078071182548796\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from operator import itemgetter\n",
    "\n",
    "REC_NUMBER = 10\n",
    "similarity_user = 50\n",
    "\n",
    "def SplitData(filename, M, seed):           #读取数据，分割为训练集和测试集：M表示 1/M 的样本为测试集\n",
    "    test = dict()\n",
    "    train = dict()                          #数据集以dict的方式存储，key为user id， value为user看过的movie id组成的list\n",
    "    random.seed(seed)\n",
    "    with open(filename,'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            #user, movie, rating, timestamp = line.split(' ')\n",
    "            #temp = re.split('\\s+', line)\n",
    "            temp = line.split('::')\n",
    "            user = temp[0]; movie = temp[1]; rating = temp[2]\n",
    "            user = int(user)\n",
    "            if float(rating) < 4:                   #此处int(rating)会报错；4分以下的评分忽略\n",
    "                continue\n",
    "            if random.randint(1,M) == 1:\n",
    "                if user not in test:\n",
    "                    test[user] = []\n",
    "                test[user].append(movie)\n",
    "            else:\n",
    "                if user not in train:\n",
    "                    train[user] = []\n",
    "                train[user].append(movie)\n",
    "    return test, train\n",
    "\n",
    "\n",
    "\n",
    "def UserSimilarity(train):\n",
    "    #build inverse table for item_users: it's shown that each item was selected by which users\n",
    "    item_users = {}\n",
    "    for u, items in train.items():\n",
    "        for i in items:\n",
    "            if i not in item_users:\n",
    "                item_users[i] = []\n",
    "            item_users[i].append(u)\n",
    "\n",
    "    user_sim_matrix = {}\n",
    "    for i, users in item_users.items():\n",
    "        for u in users:\n",
    "            for v in users:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                user_sim_matrix.setdefault(u, {})\n",
    "                user_sim_matrix[u].setdefault(v, 0)\n",
    "                user_sim_matrix[u][v] += 1\n",
    "\n",
    "    #calculate finial similarity matrix W\n",
    "    for u, related_users in user_sim_matrix.items():\n",
    "        for v, cuv in related_users.items():\n",
    "            user_sim_matrix[u][v] = cuv / math.sqrt(len(train[u]) * len(train[v]))\n",
    "    return user_sim_matrix\n",
    "\n",
    "def Recommend(user, train, W):\n",
    "    rank = dict()\n",
    "    k = similarity_user\n",
    "    watched_items = train[user]\n",
    "    for v, wuv in sorted(W[user].items(),key=itemgetter(1), reverse=True)[:k]:      #obtained most k user which similarity given user\n",
    "        for movie in train[v]:\n",
    "            if movie in watched_items:\n",
    "                continue\n",
    "            rank.setdefault(movie, 0)\n",
    "            rank[movie] += wuv\n",
    "    #return most n movies which have large probability given user will like these. Return type: [{movieID: similarity score}, {},...,{}]\n",
    "    return sorted(rank.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "class Evaluation():\n",
    "\n",
    "    def __init__(self, train, test, W):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.W = W\n",
    "        self.N = REC_NUMBER\n",
    "        self.hit = 0\n",
    "        self.hit_filter = 0\n",
    "        self.all = 0\n",
    "        self.recommend_items = set()\n",
    "        self.recommend_items_filter = set()\n",
    "        self.all_items = set()\n",
    "#         readfile = '.'#'./Result//11.19/1'\n",
    "#         with open(readfile + '/Pmatrix.json', 'r') as f:\n",
    "#             self.pmatrix = json.loads(f.read())\n",
    "#         with open(readfile + '/Qmatrix.json', 'r') as f:\n",
    "#             self.qmatrix = json.loads(f.read())\n",
    "\n",
    "    def run(self):\n",
    "        for user in self.train.keys():\n",
    "            for item in self.train[user]:\n",
    "                self.all_items.add(item)\n",
    "            tu = self.test.get(user, {})  # user corresponding movie list in the test.\n",
    "            Init_rank = Recommend(user, self.train, self.W)\n",
    "            rank = Init_rank[:self.N]\n",
    "            #Filter_rank = self.Filter(user, Init_rank)[:self.N]\n",
    "            for item, _ in rank:\n",
    "                if item in tu:\n",
    "                    self.hit += 1\n",
    "                self.recommend_items.add(item)\n",
    "            self.all += len(tu)\n",
    "\n",
    "#             for item, _ in Filter_rank:\n",
    "#                 if item in tu:\n",
    "#                     self.hit_filter += 1\n",
    "#                 self.recommend_items_filter.add(item)\n",
    "\n",
    "#     def Filter(self, user, InitRank):\n",
    "#         user = str(user)\n",
    "#         user_att = sorted(self.pmatrix[user].items(), key=itemgetter(1))\n",
    "#         NegativeAtt = []\n",
    "#         for i in range(10):\n",
    "#             negative, _ = user_att[i]\n",
    "#             NegativeAtt.append(negative)\n",
    "#         WillRm = []\n",
    "#         for item in self.qmatrix.keys():\n",
    "#             item_att = sorted(self.qmatrix[item].items(), key=itemgetter(1), reverse=True)[:5]\n",
    "#             for att, _ in item_att:\n",
    "#                 if att in NegativeAtt:\n",
    "#                     WillRm.append(item)\n",
    "#                     break\n",
    "#         for item, scoring in InitRank:\n",
    "#             for will_rm in WillRm:\n",
    "#                 if item == will_rm:\n",
    "#                     InitRank.remove((item, scoring))\n",
    "#         return InitRank\n",
    "\n",
    "    def Recall(self):\n",
    "        print('Recall: ', self.hit / (self.all * 1.0))\n",
    "#         print('After filtering: ', self.hit_filter / (self.all * 1.0))\n",
    "\n",
    "    def Precision(self):\n",
    "        print('Precision: ', self.hit / (len(self.train) * self.N * 1.0))\n",
    "#         print('After filtering: ', self.hit_filter / (len(self.train) * self.N * 1.0))\n",
    "\n",
    "    def Coverage(self):\n",
    "        print('Coverage: ', len(self.recommend_items) / (len(self.all_items) * 1.0))\n",
    "#         print('After filtering: ', len(self.recommend_items_filter) / (len(self.all_items) * 1.0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = './Data/ratings.dat'\n",
    "    # filename = './ml-100k/u.data'\n",
    "    test, train = SplitData(filename, 5, random.random())\n",
    "    W = UserSimilarity(train)\n",
    "    result = Evaluation(train, test, W)\n",
    "    result.run()\n",
    "    result.Precision()\n",
    "    print('\\n')\n",
    "    result.Recall()\n",
    "    print('\\n')\n",
    "    result.Coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.23074374689415272\n",
      "\n",
      "\n",
      "Recall:  0.12057474249112785\n",
      "\n",
      "\n",
      "Coverage:  0.17081545064377682\n"
     ]
    }
   ],
   "source": [
    "filename = './Data/ratings.dat'\n",
    "# filename = './ml-100k/u.data'\n",
    "test, train = SplitData(filename, 5, random.random())\n",
    "W = UserSimilarity(train)\n",
    "result = Evaluation(train, test, W)\n",
    "result.run()\n",
    "result.Precision()\n",
    "print('\\n')\n",
    "result.Recall()\n",
    "print('\\n')\n",
    "result.Coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.1469272817624648\n",
      "\n",
      "\n",
      "Recall:  0.07677659482385528\n",
      "\n",
      "\n",
      "Coverage:  0.0709585121602289\n"
     ]
    }
   ],
   "source": [
    "result = Evaluation(train, test, user_sim_matrix)\n",
    "result.run()\n",
    "result.Precision()\n",
    "print('\\n')\n",
    "result.Recall()\n",
    "print('\\n')\n",
    "result.Coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
